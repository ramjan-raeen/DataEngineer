{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caaa2e32-5a2e-48f1-8a16-f10ffe197bf1",
   "metadata": {},
   "source": [
    "# Basic of pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2473d-226c-46c4-9a50-0363f3257946",
   "metadata": {},
   "source": [
    "## Initialize and import library from spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ed421-1dbe-4bbf-a2a9-cbc8424c20fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f49329-9d63-4b3d-8e56-5a7d528b272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f9da10-0a49-4f2c-a4e0-89b54fd6a5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303e9ec1-881b-48cc-b54b-7e8d73148a5f",
   "metadata": {},
   "source": [
    "### What is findspark?\n",
    "\n",
    "findspark is a Python library that helps you locate and use Apache Spark from within a Python script or a Jupyter Notebook environment, especially when Spark is not installed in the system environment variables.\n",
    "\n",
    "\n",
    "findspark is a Python library that helps you locate and use Apache Spark from within a Python script or a Jupyter Notebook environment, especially when Spark is not installed in the system environment variables.\n",
    "\n",
    "When you install Spark, you typically need to set certain environment variables such as SPARK_HOME and update the PYTHONPATH to include the Spark Python libraries. findspark automates this process by searching for the Spark installation directory and adding it to the PYTHONPATH, making it easier to work with Spark in Python scripts and notebooks.\n",
    "\n",
    "Here's a typical use case for findspark:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f451481-bbe2-49be-b475-d21ac8a6ef95",
   "metadata": {},
   "source": [
    "By using findspark, you can seamlessly integrate Spark into your Python environment without manually configuring environment variables. This is particularly useful in development or testing environments where you want to quickly set up and work with Spark without dealing with environment configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4dd33e-700d-4752-a0bc-d8eebb871112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99596898-be3b-40e4-88ec-a1cc75870c06",
   "metadata": {},
   "source": [
    "### What is pyspark and why we use pyspark\n",
    "\n",
    "\n",
    "PySpark is the Python API for Apache Spark, a powerful open-source distributed computing system. Here are some details about PySpark:\n",
    "\n",
    "**Apache Spark**: Apache Spark is a fast and general-purpose cluster computing system. It provides high-level APIs in several programming languages, including Scala, Java, Python, and R, for building parallel applications. Spark is designed for distributed processing of large-scale data sets across clusters of computers.\n",
    "\n",
    "**Python API (PySpark)**: PySpark is the Python API for Apache Spark. It allows Python developers to leverage the power of Spark for data processing and analysis using familiar Python programming constructs. PySpark provides an easy-to-use interface for interacting with Spark's distributed computing engine, enabling scalable and efficient data processing.\n",
    "\n",
    "**Features:**\n",
    "\n",
    "* Distributed Computing: PySpark enables distributed processing of data across a cluster of machines, allowing you to scale your data processing tasks horizontally.\n",
    "* In-Memory Computation: Spark uses in-memory processing to speed up data processing tasks, making it suitable for iterative algorithms and interactive data analysis.\n",
    "* Rich Ecosystem: Spark comes with a rich set of libraries and tools for various data processing tasks, including SQL queries (Spark SQL), machine learning (MLlib), graph processing (GraphX), and streaming analytics (Spark Streaming).\n",
    "* Ease of Use: PySpark provides a user-friendly API that abstracts away the complexities of distributed computing, making it easier for Python developers to work with large-scale data sets.\n",
    "* Integration: PySpark integrates seamlessly with other Python libraries and frameworks such as Pandas, NumPy, Matplotlib, and Scikit-learn, allowing you to leverage the strengths of these libraries in conjunction with Spark.\n",
    "* Components: PySpark includes several components that work together to enable distributed data processing:\n",
    "\n",
    "**Spark Core**: The foundational component of Spark that provides distributed task scheduling, fault tolerance, and memory management.\n",
    "* Spark SQL: A module for working with structured data using SQL queries, DataFrames, and Datasets.\n",
    "* MLlib: Spark's machine learning library that provides scalable implementations of machine learning algorithms.\n",
    "* GraphX: A graph processing library for analyzing and processing graph data.\n",
    "* Spark Streaming: A real-time streaming processing library for processing continuous streams of data.\n",
    "**Use Cases**: PySpark is used in a wide range of industries and applications, including big data analytics, data warehousing, machine learning, real-time analytics, and more. It's particularly well-suited for processing large volumes of data efficiently and performing complex analytics tasks at scale.\n",
    "\n",
    "Overall, PySpark is a versatile and powerful tool for building scalable and efficient data processing applications using Python, leveraging the distributed computing capabilities of Apache Spark.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018acfd-4a24-4e25-8338-1bfca6a486f0",
   "metadata": {},
   "source": [
    "### What is Hive? what is benifite use of Hive.\n",
    "\n",
    "Hive is an open-source data warehouse infrastructure built on top of Apache Hadoop for providing data summarization, query, and analysis. Here are some key details about Hive:\n",
    "\n",
    "**SQL-like Query Language**: Hive provides a SQL-like query language called HiveQL (HQL) that allows users to write queries to analyze and process large datasets stored in Hadoop Distributed File System (HDFS) or other compatible file systems. HiveQL syntax is similar to SQL, making it familiar and accessible to users who are already familiar with SQL.\n",
    "\n",
    "**Data Warehousing**: Hive is designed for data warehousing and analytical processing of large datasets. It enables users to run ad-hoc queries, generate reports, and perform data analysis on massive volumes of structured and semi-structured data stored in Hadoop.\n",
    "\n",
    "**Schema-on-Read:** Unlike traditional relational databases where data schema is defined upfront, Hive follows a schema-on-read approach. This means that data stored in Hadoop is stored in a raw format, and the schema is applied at the time of querying the data. This provides flexibility in handling diverse and evolving data schemas.\n",
    "\n",
    "**Metastore:** Hive includes a metastore, which is a centralized repository that stores metadata information such as table schemas, partition information, column statistics, and storage location of data files. The metastore helps manage the metadata associated with Hive tables and partitions, making it easier to manage and query large datasets.\n",
    "\n",
    "**Integration with Hadoop Ecosystem:** Hive seamlessly integrates with other components of the Hadoop ecosystem, including Hadoop Distributed File System (HDFS), Hadoop MapReduce, Apache Tez, Apache Spark, and others. This integration allows users to leverage the scalability and fault tolerance of Hadoop for processing and analyzing large datasets.\n",
    "\n",
    "**Extensible Architecture:** Hive's architecture is extensible, allowing users to plug in custom extensions and UDFs (User-Defined Functions) to extend its functionality. Users can write custom functions in programming languages such as Java, Python, or Scala and integrate them into Hive queries.\n",
    "\n",
    "**Use Cases:** Hive is widely used in various industries and domains for data warehousing, business intelligence, data analysis, and reporting. It is particularly well-suited for batch processing and analytical workloads on large volumes of structured and semi-structured data.\n",
    "\n",
    "Overall, Hive provides a powerful and scalable solution for data warehousing and analytical processing of big data on Hadoop, enabling organizations to derive insights from large datasets stored in distributed environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f8946e-a563-4289-a0a6-9734685ed994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.sql.types import TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efb47f2-ac18-4356-a930-9b05d202b85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/19 23:08:50 WARN Utils: Your hostname, localhost resolves to a loopback address: 127.0.0.1; using 192.168.1.106 instead (on interface wlp1s0)\n",
      "24/03/19 23:08:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/19 23:08:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"MyApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f11c54-b934-483d-ab32-0cc13c914f0a",
   "metadata": {},
   "source": [
    "## Initalize dummy data and create spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "198c5644-11bf-4aee-945b-c77616c1e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",None), \\\n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",None) \\\n",
    "  ]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\\n",
    "       \"emp_dept_id\",\"gender\",\"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9a706b5-48b7-47f1-92a7-b85b9b578749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
      "|5     |Brown   |2              |2010       |40         |      |NULL  |\n",
      "|6     |Brown   |2              |2010       |50         |      |NULL  |\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df = spark.createDataFrame(data=emp, schema=empColumns)\n",
    "emp_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e814407-af7a-4e91-959d-ed73acc66089",
   "metadata": {},
   "source": [
    "## Find null values\n",
    "\n",
    "**Find null value into salary column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f002b6-9ba5-480f-bee9-608742603cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|null_count|\n",
      "+----------+\n",
      "|         2|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(F.sum(F.col(\"salary\").isNull().cast('int')).alias(\"null_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fafd567-c32a-48de-a213-324ebf6b3e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+----+---------------+-----------+-----------+------+------+\n",
      "|     0|   0|              0|          0|          0|     0|     2|\n",
      "+------+----+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select([F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in emp_df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365916b2-d5fe-47ff-a990-e1ceb0110c6a",
   "metadata": {},
   "source": [
    "**Cosider an empty value as null value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c4c0d6-cedc-4b54-a24b-8edb2933d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+----+---------------+-----------+-----------+------+------+\n",
      "|     0|   0|              0|          0|          0|     2|     2|\n",
      "+------+----+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select([F.sum(F.when((F.col(c)==\"\" )| (F.col(c).isNull()), 1).otherwise(0)).alias(c) for c in emp_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95926ccb-2390-4a63-b358-60253a159eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----------------------+------------------+------------------+-------------+-------------+\n",
      "|emp_id_isNull|name_isNull|superior_emp_id_isNull|year_joined_isNull|emp_dept_id_isNull|gender_isNull|salary_isNull|\n",
      "+-------------+-----------+----------------------+------------------+------------------+-------------+-------------+\n",
      "|0            |0          |0                     |0                 |0                 |2            |2            |\n",
      "+-------------+-----------+----------------------+------------------+------------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select([F.sum(F.when((F.col(c)==\"\" )| \\\n",
    "                            (F.col(c).isNull()), 1).otherwise(0)).alias(f\"{c}_isNull\") \\\n",
    "               \n",
    "               for c in emp_df.columns]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80710f8-dae5-4ac6-897f-ee3307a4f261",
   "metadata": {},
   "source": [
    "## Rename column name using \n",
    "withColumn, selectExpr, withColumnRenamed and alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aedaa60b-a05e-49b1-a61b-202a571ff1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+----+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|YOJ |\n",
      "+------+--------+---------------+-----------+-----------+------+------+----+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |2018|\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |2010|\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |2010|\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |2005|\n",
      "|5     |Brown   |2              |2010       |40         |      |NULL  |2010|\n",
      "|6     |Brown   |2              |2010       |50         |      |NULL  |2010|\n",
      "+------+--------+---------------+-----------+-----------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.withColumn(\"YOJ\", F.col(\"year_joined\"))\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb233cd7-8a24-437b-827f-2eb87dacab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------+\n",
      "|emp_id|YOJ |Name    |\n",
      "+------+----+--------+\n",
      "|1     |2018|Smith   |\n",
      "|2     |2010|Rose    |\n",
      "|3     |2010|Williams|\n",
      "|4     |2005|Jones   |\n",
      "|5     |2010|Brown   |\n",
      "|6     |2010|Brown   |\n",
      "+------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.selectExpr(\"emp_id\", \"year_joined as YOJ\", \"name as Name\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75de622f-27ea-4584-a8d8-f069993b22fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------+\n",
      "|emp_id|YOJ |Name    |\n",
      "+------+----+--------+\n",
      "|1     |2018|Smith   |\n",
      "|2     |2010|Rose    |\n",
      "|3     |2010|Williams|\n",
      "|4     |2005|Jones   |\n",
      "|5     |2010|Brown   |\n",
      "|6     |2010|Brown   |\n",
      "+------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"emp_id\", \"YOJ\", \"Name\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ce7a4be-6a42-4006-83ff-29d124e087b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+----+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|YOJ |emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+----+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018|10         |M     |3000  |\n",
      "|2     |Rose    |1              |2010|20         |M     |4000  |\n",
      "|3     |Williams|1              |2010|10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005|10         |F     |2000  |\n",
      "|5     |Brown   |2              |2010|40         |      |NULL  |\n",
      "|6     |Brown   |2              |2010|50         |      |NULL  |\n",
      "+------+--------+---------------+----+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.withColumnRenamed(\"year_joined\", \"YOJ\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "626eca29-68a1-43d6-ba89-619856e82676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|    Name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
      "|     5|   Brown|              2|       2010|         40|      |  NULL|\n",
      "|     6|   Brown|              2|       2010|         50|      |  NULL|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.withColumnRenamed(\"year_joied\", \"yoj\")\\\n",
    "            .withColumnRenamed(\"name\", \"Name\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e8870f2-6611-4454-8522-e341c39b428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+----+-----------+---+------+\n",
      "|emp_id|Name    |sup_emp_id|YOJ |emp_dept_id|GEN|salary|\n",
      "+------+--------+----------+----+-----------+---+------+\n",
      "|1     |Smith   |-1        |2018|10         |M  |3000  |\n",
      "|2     |Rose    |1         |2010|20         |M  |4000  |\n",
      "|3     |Williams|1         |2010|10         |M  |1000  |\n",
      "|4     |Jones   |2         |2005|10         |F  |2000  |\n",
      "|5     |Brown   |2         |2010|40         |   |NULL  |\n",
      "|6     |Brown   |2         |2010|50         |   |NULL  |\n",
      "+------+--------+----------+----+-----------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.select(\"emp_id\", \"Name\", \\\n",
    "                   F.col(\"superior_emp_id\").alias(\"sup_emp_id\"), \\\n",
    "                   F.col(\"year_joined\").alias(\"YOJ\"), \\\n",
    "                   \"emp_dept_id\", \\\n",
    "                   F.col(\"gender\").alias(\"GEN\"), \\\n",
    "                   \"salary\")\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "254b253f-c0a0-48ab-ab03-b38d883cdfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af4770-aef8-4d2e-abcb-6033434bbeb0",
   "metadata": {},
   "source": [
    "## Use of filter and where function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7d2de0f-f79b-4b5e-b2d5-645e226802c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+\n",
      "|emp_id|    name|salary|\n",
      "+------+--------+------+\n",
      "|     1|   Smith|  3000|\n",
      "|     3|Williams|  1000|\n",
      "|     4|   Jones|  2000|\n",
      "+------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.select(\"emp_id\", \"name\", \"salary\").filter(F.col(\"salary\")<=3000)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6ac6ee1-dea1-4ac6-af68-c79bae3326d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|emp_id| name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|     2| Rose|              1|       2010|         20|     M|  4000|\n",
      "|     5|Brown|              2|       2010|         40|      |  NULL|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.filter((F.col(\"emp_dept_id\")>=20) & (F.col(\"emp_dept_id\") <50))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1055c4bd-b350-4112-9809-302d31719853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|emp_id| name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|     1|Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     2| Rose|              1|       2010|         20|     M|  4000|\n",
      "|     4|Jones|              2|       2005|         10|     F|  2000|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(\"*\").filter((F.col(\"salary\") >=2000) & (F.col(\"salary\") < 5000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5474f91d-5ac3-44e1-8edf-5becf4819402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+\n",
      "|emp_id|name    |salary|\n",
      "+------+--------+------+\n",
      "|1     |Smith   |3000  |\n",
      "|3     |Williams|1000  |\n",
      "|4     |Jones   |2000  |\n",
      "+------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.select(\"emp_id\", \"name\", \"salary\").where(\"salary <=3000\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "654b8970-e2d3-4bbb-9a8a-c20633369337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|emp_id| name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|     1|Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     2| Rose|              1|       2010|         20|     M|  4000|\n",
      "|     4|Jones|              2|       2005|         10|     F|  2000|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.where(\"salary >= 2000 and salary < 5000\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bab8bab0-ad04-4190-be00-663c40b79f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b92d3-f309-4d5e-9907-c31a9d15ea53",
   "metadata": {},
   "source": [
    "## Use of aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c36831d8-eefe-4805-94d2-10b085afbf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|emp_dept_id|dept_wise_sal|\n",
      "+-----------+-------------+\n",
      "|         40|         NULL|\n",
      "|         20|         4000|\n",
      "|         10|         6000|\n",
      "|         50|         NULL|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gpby = emp_df.groupBy(\"emp_dept_id\").agg(F.sum(\"salary\").alias(\"dept_wise_sal\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5881e254-a5f4-414b-a812-3e60f5b21fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+\n",
      "|emp_dept_id|superior_emp_id|aggregate_sum|\n",
      "+-----------+---------------+-------------+\n",
      "|         40|              2|         NULL|\n",
      "|         10|              2|         2000|\n",
      "|         20|              1|         4000|\n",
      "|         10|              1|         1000|\n",
      "|         10|             -1|         3000|\n",
      "|         50|              2|         NULL|\n",
      "+-----------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.groupBy(\"emp_dept_id\", \"superior_emp_id\").agg(F.sum(\"salary\").alias(\"aggregate_sum\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "204a9ddf-3464-42bf-952e-397431092298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25df3db-61b8-4ecf-a0e2-99d3abcf135e",
   "metadata": {},
   "source": [
    "**cast the data type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f87d1f38-35d8-4f56-84c7-fad1d15070eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+------+------+\n",
      "|emp_id|    name|superior_emp_id|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+------+------+\n",
      "|     1|   Smith|             -1|         10|     M|  3000|\n",
      "|     2|    Rose|              1|         20|     M|  4000|\n",
      "|     3|Williams|              1|         10|     M|  1000|\n",
      "|     4|   Jones|              2|         10|     F|  2000|\n",
      "|     5|   Brown|              2|         40|      |  NULL|\n",
      "|     6|   Brown|              2|         50|      |  NULL|\n",
      "+------+--------+---------------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.select(F.col(\"emp_id\"), \\\n",
    "                   F.col(\"name\"), \\\n",
    "                   F.col(\"superior_emp_id\"), \\\n",
    "                   F.col(\"emp_dept_id\"), \\\n",
    "                   F.col(\"gender\"), \\\n",
    "                   F.col(\"salary\").cast(\"int\").alias(\"salary\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f4ff870-541b-48c5-98ed-128610827468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d4416d4-d3a0-46e3-9cb0-6b770d7142cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
      "|     5|   Brown|              2|       2010|         40|      |     0|\n",
      "|     6|   Brown|              2|       2010|         50|      |     0|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = emp_df.withColumn(\"salary\", F.when(F.col(\"salary\").cast(\"int\").isNull(), 0).otherwise(F.col(\"salary\").cast('int')))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89c1e669-6d08-4298-87a5-d11a16bc34fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|emp_dept_id|total_sal|\n",
      "+-----------+---------+\n",
      "|         40|        0|\n",
      "|         20|     4000|\n",
      "|         10|     6000|\n",
      "|         50|        0|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"emp_dept_id\").agg(F.sum(\"salary\").alias(\"total_sal\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d80e3b-0ac9-43e3-8c9f-d6f53f252e61",
   "metadata": {},
   "source": [
    "## Use of when function\n",
    "`when()` can use for `if else` condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bffea937-55f8-4ef6-884c-e265293f4afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+----------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|sup_emp_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+----------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|         A|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|         1|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|         1|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|         1|\n",
      "|     5|   Brown|              2|       2010|         40|      |     0|         1|\n",
      "|     6|   Brown|              2|       2010|         50|      |     0|         1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"sup_emp_id\", F.when(F.col(\"superior_emp_id\")>0, 1).otherwise(\"A\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d492a95e-949e-400a-9b5c-544058915fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|emp_dept_id|salary|\n",
      "+-----------+------+\n",
      "|         40|     0|\n",
      "|         20|  4000|\n",
      "|         10|  6000|\n",
      "|         50|     0|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupBy_df = df.groupBy(\"emp_dept_id\").agg(F.sum(\"salary\").alias(\"salary\"))\n",
    "groupBy_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dbb681-e473-4503-bf8d-ed823a8bd851",
   "metadata": {},
   "source": [
    "## Find unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d2a1f87-047a-4790-8d7c-e589706c0d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(superior_emp_id=1), Row(superior_emp_id=2), Row(superior_emp_id=-1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_val = df.select(\"superior_emp_id\").distinct().collect()\n",
    "dist_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "277e2068-9706-4d33-b213-316fd343925a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, -1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sup_emp_id = [r.superior_emp_id for r in dist_val]\n",
    "unique_sup_emp_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b89bdd3-43dc-4218-b0ba-d156fba4d335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b21cb2-3d6e-4ece-a29f-18448feca733",
   "metadata": {},
   "source": [
    "# Read data from local machne and create spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5046328-0153-4700-b405-e370c693521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " auto-mpg.csv\t\t\t\t  kc_house_data.csv\n",
      " brand-laptops-dataset.zip\t\t  laptops.csv\n",
      " covid.json\t\t\t\t  train_info.csv\n",
      " Employee.csv\t\t\t\t  train_schedule.csv\n",
      "'IEA-EV-dataEV salesCarsHistorical.csv'   train_schedule.csv.zip\n",
      " indian_states_code_name_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "!ls datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a411c8f-b40f-4d8b-8acc-9bfcd86f9e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|id        |date           |price    |bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|grade|sqft_above|sqft_basement|yr_built|yr_renovated|zipcode|lat    |long    |sqft_living15|sqft_lot15|\n",
      "+----------+---------------+---------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|7129300520|20141013T000000|221900.0 |3       |1.0      |1180       |5650    |1.0   |0         |0   |3        |7    |1180      |0            |1955    |0           |98178  |47.5112|-122.257|1340         |5650      |\n",
      "|6414100192|20141209T000000|538000.0 |3       |2.25     |2570       |7242    |2.0   |0         |0   |3        |7    |2170      |400          |1951    |1991        |98125  |47.721 |-122.319|1690         |7639      |\n",
      "|5631500400|20150225T000000|180000.0 |2       |1.0      |770        |10000   |1.0   |0         |0   |3        |6    |770       |0            |1933    |0           |98028  |47.7379|-122.233|2720         |8062      |\n",
      "|2487200875|20141209T000000|604000.0 |4       |3.0      |1960       |5000    |1.0   |0         |0   |5        |7    |1050      |910          |1965    |0           |98136  |47.5208|-122.393|1360         |5000      |\n",
      "|1954400510|20150218T000000|510000.0 |3       |2.0      |1680       |8080    |1.0   |0         |0   |3        |8    |1680      |0            |1987    |0           |98074  |47.6168|-122.045|1800         |7503      |\n",
      "|7237550310|20140512T000000|1225000.0|4       |4.5      |5420       |101930  |1.0   |0         |0   |3        |11   |3890      |1530         |2001    |0           |98053  |47.6561|-122.005|4760         |101930    |\n",
      "|1321400060|20140627T000000|257500.0 |3       |2.25     |1715       |6819    |2.0   |0         |0   |3        |7    |1715      |0            |1995    |0           |98003  |47.3097|-122.327|2238         |6819      |\n",
      "|2008000270|20150115T000000|291850.0 |3       |1.5      |1060       |9711    |1.0   |0         |0   |3        |7    |1060      |0            |1963    |0           |98198  |47.4095|-122.315|1650         |9711      |\n",
      "|2414600126|20150415T000000|229500.0 |3       |1.0      |1780       |7470    |1.0   |0         |0   |3        |7    |1050      |730          |1960    |0           |98146  |47.5123|-122.337|1780         |8113      |\n",
      "|3793500160|20150312T000000|323000.0 |3       |2.5      |1890       |6560    |2.0   |0         |0   |3        |7    |1890      |0            |2003    |0           |98038  |47.3684|-122.031|2390         |7570      |\n",
      "|1736800520|20150403T000000|662500.0 |3       |2.5      |3560       |9796    |1.0   |0         |0   |3        |8    |1860      |1700         |1965    |0           |98007  |47.6007|-122.145|2210         |8925      |\n",
      "|9212900260|20140527T000000|468000.0 |2       |1.0      |1160       |6000    |1.0   |0         |0   |4        |7    |860       |300          |1942    |0           |98115  |47.69  |-122.292|1330         |6000      |\n",
      "|114101516 |20140528T000000|310000.0 |3       |1.0      |1430       |19901   |1.5   |0         |0   |4        |7    |1430      |0            |1927    |0           |98028  |47.7558|-122.229|1780         |12697     |\n",
      "|6054650070|20141007T000000|400000.0 |3       |1.75     |1370       |9680    |1.0   |0         |0   |4        |7    |1370      |0            |1977    |0           |98074  |47.6127|-122.045|1370         |10208     |\n",
      "|1175000570|20150312T000000|530000.0 |5       |2.0      |1810       |4850    |1.5   |0         |0   |3        |7    |1810      |0            |1900    |0           |98107  |47.67  |-122.394|1360         |4850      |\n",
      "|9297300055|20150124T000000|650000.0 |4       |3.0      |2950       |5000    |2.0   |0         |3   |3        |9    |1980      |970          |1979    |0           |98126  |47.5714|-122.375|2140         |4000      |\n",
      "|1875500060|20140731T000000|395000.0 |3       |2.0      |1890       |14040   |2.0   |0         |0   |3        |7    |1890      |0            |1994    |0           |98019  |47.7277|-121.962|1890         |14018     |\n",
      "|6865200140|20140529T000000|485000.0 |4       |1.0      |1600       |4300    |1.5   |0         |0   |4        |7    |1600      |0            |1916    |0           |98103  |47.6648|-122.343|1610         |4300      |\n",
      "|16000397  |20141205T000000|189000.0 |2       |1.0      |1200       |9850    |1.0   |0         |0   |4        |7    |1200      |0            |1921    |0           |98002  |47.3089|-122.21 |1060         |5095      |\n",
      "|7983200060|20150424T000000|230000.0 |3       |1.0      |1250       |9774    |1.0   |0         |0   |4        |7    |1250      |0            |1969    |0           |98003  |47.3343|-122.306|1280         |8850      |\n",
      "+----------+---------------+---------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "house_df = spark.read.format(\"csv\")\\\n",
    "                .option(\"inferSchema\", True)\\\n",
    "                .option(\"header\", True)\\\n",
    "                .load(\"datasets/kc_house_data.csv\")\n",
    "\n",
    "\n",
    "house_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b800db7-92d2-40ba-aeef-b44319ab8638",
   "metadata": {},
   "source": [
    "## List all columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bd7aee1-6060-4f4e-9d33-4a40439f9e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'date',\n",
       " 'price',\n",
       " 'bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot15']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778856d-557d-4fad-a68a-fbac5da6a79a",
   "metadata": {},
   "source": [
    "## select list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a856906f-1027-4c9f-a815-fabe91e04af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------+--------+------+----------+----+-----+---------+--------+------------+---------------+---------+\n",
      "|id        |bedrooms|sqft_living|sqft_lot|floors|waterfront|view|grade|condition|yr_built|yr_renovated|date           |price    |\n",
      "+----------+--------+-----------+--------+------+----------+----+-----+---------+--------+------------+---------------+---------+\n",
      "|7129300520|3       |1180       |5650    |1.0   |0         |0   |7    |3        |1955    |0           |20141013T000000|221900.0 |\n",
      "|6414100192|3       |2570       |7242    |2.0   |0         |0   |7    |3        |1951    |1991        |20141209T000000|538000.0 |\n",
      "|5631500400|2       |770        |10000   |1.0   |0         |0   |6    |3        |1933    |0           |20150225T000000|180000.0 |\n",
      "|2487200875|4       |1960       |5000    |1.0   |0         |0   |7    |5        |1965    |0           |20141209T000000|604000.0 |\n",
      "|1954400510|3       |1680       |8080    |1.0   |0         |0   |8    |3        |1987    |0           |20150218T000000|510000.0 |\n",
      "|7237550310|4       |5420       |101930  |1.0   |0         |0   |11   |3        |2001    |0           |20140512T000000|1225000.0|\n",
      "|1321400060|3       |1715       |6819    |2.0   |0         |0   |7    |3        |1995    |0           |20140627T000000|257500.0 |\n",
      "|2008000270|3       |1060       |9711    |1.0   |0         |0   |7    |3        |1963    |0           |20150115T000000|291850.0 |\n",
      "|2414600126|3       |1780       |7470    |1.0   |0         |0   |7    |3        |1960    |0           |20150415T000000|229500.0 |\n",
      "|3793500160|3       |1890       |6560    |2.0   |0         |0   |7    |3        |2003    |0           |20150312T000000|323000.0 |\n",
      "|1736800520|3       |3560       |9796    |1.0   |0         |0   |8    |3        |1965    |0           |20150403T000000|662500.0 |\n",
      "|9212900260|2       |1160       |6000    |1.0   |0         |0   |7    |4        |1942    |0           |20140527T000000|468000.0 |\n",
      "|114101516 |3       |1430       |19901   |1.5   |0         |0   |7    |4        |1927    |0           |20140528T000000|310000.0 |\n",
      "|6054650070|3       |1370       |9680    |1.0   |0         |0   |7    |4        |1977    |0           |20141007T000000|400000.0 |\n",
      "|1175000570|5       |1810       |4850    |1.5   |0         |0   |7    |3        |1900    |0           |20150312T000000|530000.0 |\n",
      "|9297300055|4       |2950       |5000    |2.0   |0         |3   |9    |3        |1979    |0           |20150124T000000|650000.0 |\n",
      "|1875500060|3       |1890       |14040   |2.0   |0         |0   |7    |3        |1994    |0           |20140731T000000|395000.0 |\n",
      "|6865200140|4       |1600       |4300    |1.5   |0         |0   |7    |4        |1916    |0           |20140529T000000|485000.0 |\n",
      "|16000397  |2       |1200       |9850    |1.0   |0         |0   |7    |4        |1921    |0           |20141205T000000|189000.0 |\n",
      "|7983200060|3       |1250       |9774    |1.0   |0         |0   |7    |4        |1969    |0           |20150424T000000|230000.0 |\n",
      "+----------+--------+-----------+--------+------+----------+----+-----+---------+--------+------------+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = house_df.select(\"id\", \"bedrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\", \n",
    "                     \"view\",\"grade\",\"condition\",\"yr_built\",\"yr_renovated\", \"date\",\"price\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26d5c72d-4f5e-48f1-ab70-e1538e116214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- sqft_living: integer (nullable = true)\n",
      " |-- sqft_lot: integer (nullable = true)\n",
      " |-- floors: double (nullable = true)\n",
      " |-- waterfront: integer (nullable = true)\n",
      " |-- view: integer (nullable = true)\n",
      " |-- grade: integer (nullable = true)\n",
      " |-- condition: integer (nullable = true)\n",
      " |-- yr_built: integer (nullable = true)\n",
      " |-- yr_renovated: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ecc493-881f-45f2-a868-7e4cc43e8962",
   "metadata": {},
   "source": [
    "## Total grade types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a71c1387-59d4-4544-983d-b6a8c599d1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(grade=12),\n",
       " Row(grade=1),\n",
       " Row(grade=13),\n",
       " Row(grade=6),\n",
       " Row(grade=3),\n",
       " Row(grade=5),\n",
       " Row(grade=9),\n",
       " Row(grade=4),\n",
       " Row(grade=8),\n",
       " Row(grade=7),\n",
       " Row(grade=10),\n",
       " Row(grade=11)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_type = df.select(\"grade\").distinct().collect()\n",
    "grade_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63fe0d46-f52a-4db5-aafb-f19435a15e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_type = [row.grade for row in grade_type]\n",
    "grade_type.sort()\n",
    "grade_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4bc6f4-64d6-475e-a532-b328ebb34e14",
   "metadata": {},
   "source": [
    "## Count total grade type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fc66633-17fd-4028-9497-0faa546c8caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+\n",
      "|grade|total_grade_type|\n",
      "+-----+----------------+\n",
      "|   12|              90|\n",
      "|    1|               1|\n",
      "|   13|              13|\n",
      "|    6|            2038|\n",
      "|    3|               3|\n",
      "|    5|             242|\n",
      "|    9|            2615|\n",
      "|    4|              29|\n",
      "|    8|            6068|\n",
      "|    7|            8981|\n",
      "|   10|            1134|\n",
      "|   11|             399|\n",
      "+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"grade\").agg(F.count(\"grade\").alias(\"total_grade_type\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be431d09-e2b4-41b7-8f64-da09f5d0cd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------+--------+-----+---------+--------+------------+---------------+---------+\n",
      "|id        |bedrooms|sqft_living|sqft_lot|grade|condition|yr_built|yr_renovated|date           |price    |\n",
      "+----------+--------+-----------+--------+-----+---------+--------+------------+---------------+---------+\n",
      "|7129300520|3       |1180       |5650    |7    |3        |1955    |0           |20141013T000000|221900.0 |\n",
      "|6414100192|3       |2570       |7242    |7    |3        |1951    |1991        |20141209T000000|538000.0 |\n",
      "|1954400510|3       |1680       |8080    |8    |3        |1987    |0           |20150218T000000|510000.0 |\n",
      "|1321400060|3       |1715       |6819    |7    |3        |1995    |0           |20140627T000000|257500.0 |\n",
      "|2008000270|3       |1060       |9711    |7    |3        |1963    |0           |20150115T000000|291850.0 |\n",
      "|2414600126|3       |1780       |7470    |7    |3        |1960    |0           |20150415T000000|229500.0 |\n",
      "|3793500160|3       |1890       |6560    |7    |3        |2003    |0           |20150312T000000|323000.0 |\n",
      "|1736800520|3       |3560       |9796    |8    |3        |1965    |0           |20150403T000000|662500.0 |\n",
      "|114101516 |3       |1430       |19901   |7    |4        |1927    |0           |20140528T000000|310000.0 |\n",
      "|6054650070|3       |1370       |9680    |7    |4        |1977    |0           |20141007T000000|400000.0 |\n",
      "|1875500060|3       |1890       |14040   |7    |3        |1994    |0           |20140731T000000|395000.0 |\n",
      "|7983200060|3       |1250       |9774    |7    |4        |1969    |0           |20150424T000000|230000.0 |\n",
      "|2524049179|3       |3050       |44867   |9    |3        |1968    |0           |20140826T000000|2000000.0|\n",
      "|3814700200|3       |2450       |6500    |8    |4        |1985    |0           |20141120T000000|329000.0 |\n",
      "|1202000200|3       |1710       |4697    |6    |5        |1941    |0           |20141103T000000|233000.0 |\n",
      "|1794500383|3       |2450       |2691    |8    |3        |1915    |0           |20140626T000000|937000.0 |\n",
      "|3303700376|3       |1400       |1581    |8    |5        |1909    |0           |20141201T000000|667000.0 |\n",
      "|5101402488|3       |1520       |6380    |7    |3        |1948    |0           |20140624T000000|438000.0 |\n",
      "|8562750320|3       |2320       |3980    |8    |3        |2003    |0           |20141110T000000|580500.0 |\n",
      "|7589200193|3       |1090       |3000    |8    |4        |1929    |0           |20141110T000000|535000.0 |\n",
      "+----------+--------+-----------+--------+-----+---------+--------+------------+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"id\", \"bedrooms\", \"sqft_living\", \"sqft_lot\", \"grade\", \"condition\", \"yr_built\", \"yr_renovated\", \"date\", \"price\")\\\n",
    "    .filter(F.col(\"bedrooms\")==3).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab40943-e43e-4226-93e7-638d4a1a742f",
   "metadata": {},
   "source": [
    "## Convert string datetime to actual datetime timestamp data type\n",
    "See below, date column which datetimestamp as string data type. convert into it datetimestamp data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8133084-88c4-402b-9f48-067958385423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- sqft_living: integer (nullable = true)\n",
      " |-- sqft_lot: integer (nullable = true)\n",
      " |-- floors: double (nullable = true)\n",
      " |-- waterfront: integer (nullable = true)\n",
      " |-- view: integer (nullable = true)\n",
      " |-- grade: integer (nullable = true)\n",
      " |-- condition: integer (nullable = true)\n",
      " |-- yr_built: integer (nullable = true)\n",
      " |-- yr_renovated: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0d1cf37-4655-49e9-b734-285f411161f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------+--------+------+----------+----+-----+---------+--------+------------+---------+-------------------+\n",
      "|        id|bedrooms|sqft_living|sqft_lot|floors|waterfront|view|grade|condition|yr_built|yr_renovated|    price|           datetime|\n",
      "+----------+--------+-----------+--------+------+----------+----+-----+---------+--------+------------+---------+-------------------+\n",
      "|7129300520|       3|       1180|    5650|   1.0|         0|   0|    7|        3|    1955|           0| 221900.0|2014-10-13 00:00:00|\n",
      "|6414100192|       3|       2570|    7242|   2.0|         0|   0|    7|        3|    1951|        1991| 538000.0|2014-12-09 00:00:00|\n",
      "|5631500400|       2|        770|   10000|   1.0|         0|   0|    6|        3|    1933|           0| 180000.0|2015-02-25 00:00:00|\n",
      "|2487200875|       4|       1960|    5000|   1.0|         0|   0|    7|        5|    1965|           0| 604000.0|2014-12-09 00:00:00|\n",
      "|1954400510|       3|       1680|    8080|   1.0|         0|   0|    8|        3|    1987|           0| 510000.0|2015-02-18 00:00:00|\n",
      "|7237550310|       4|       5420|  101930|   1.0|         0|   0|   11|        3|    2001|           0|1225000.0|2014-05-12 00:00:00|\n",
      "|1321400060|       3|       1715|    6819|   2.0|         0|   0|    7|        3|    1995|           0| 257500.0|2014-06-27 00:00:00|\n",
      "|2008000270|       3|       1060|    9711|   1.0|         0|   0|    7|        3|    1963|           0| 291850.0|2015-01-15 00:00:00|\n",
      "|2414600126|       3|       1780|    7470|   1.0|         0|   0|    7|        3|    1960|           0| 229500.0|2015-04-15 00:00:00|\n",
      "|3793500160|       3|       1890|    6560|   2.0|         0|   0|    7|        3|    2003|           0| 323000.0|2015-03-12 00:00:00|\n",
      "|1736800520|       3|       3560|    9796|   1.0|         0|   0|    8|        3|    1965|           0| 662500.0|2015-04-03 00:00:00|\n",
      "|9212900260|       2|       1160|    6000|   1.0|         0|   0|    7|        4|    1942|           0| 468000.0|2014-05-27 00:00:00|\n",
      "| 114101516|       3|       1430|   19901|   1.5|         0|   0|    7|        4|    1927|           0| 310000.0|2014-05-28 00:00:00|\n",
      "|6054650070|       3|       1370|    9680|   1.0|         0|   0|    7|        4|    1977|           0| 400000.0|2014-10-07 00:00:00|\n",
      "|1175000570|       5|       1810|    4850|   1.5|         0|   0|    7|        3|    1900|           0| 530000.0|2015-03-12 00:00:00|\n",
      "|9297300055|       4|       2950|    5000|   2.0|         0|   3|    9|        3|    1979|           0| 650000.0|2015-01-24 00:00:00|\n",
      "|1875500060|       3|       1890|   14040|   2.0|         0|   0|    7|        3|    1994|           0| 395000.0|2014-07-31 00:00:00|\n",
      "|6865200140|       4|       1600|    4300|   1.5|         0|   0|    7|        4|    1916|           0| 485000.0|2014-05-29 00:00:00|\n",
      "|  16000397|       2|       1200|    9850|   1.0|         0|   0|    7|        4|    1921|           0| 189000.0|2014-12-05 00:00:00|\n",
      "|7983200060|       3|       1250|    9774|   1.0|         0|   0|    7|        4|    1969|           0| 230000.0|2015-04-24 00:00:00|\n",
      "+----------+--------+-----------+--------+------+----------+----+-----+---------+--------+------------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ts = df.withColumn(\"datetime\", F.to_timestamp(F.col(\"date\"), 'yyyyMMdd\\'T\\'HHmmss').cast(TimestampType())).drop(\"date\")\n",
    "df_ts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46176bc9-fbaa-4102-9383-0c74752daac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- sqft_living: integer (nullable = true)\n",
      " |-- sqft_lot: integer (nullable = true)\n",
      " |-- floors: double (nullable = true)\n",
      " |-- waterfront: integer (nullable = true)\n",
      " |-- view: integer (nullable = true)\n",
      " |-- grade: integer (nullable = true)\n",
      " |-- condition: integer (nullable = true)\n",
      " |-- yr_built: integer (nullable = true)\n",
      " |-- yr_renovated: integer (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- datetime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ts.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f64da6-98cf-4697-abca-cbee0f8f4d9d",
   "metadata": {},
   "source": [
    "## Split year, month and day from datetime timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67415354-d433-4e30-9e04-7ceaee31596f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+\n",
      "|date|month|year|\n",
      "+----+-----+----+\n",
      "|  13|   10|2014|\n",
      "|   9|   12|2014|\n",
      "|  25|    2|2015|\n",
      "|   9|   12|2014|\n",
      "|  18|    2|2015|\n",
      "|  12|    5|2014|\n",
      "|  27|    6|2014|\n",
      "|  15|    1|2015|\n",
      "|  15|    4|2015|\n",
      "|  12|    3|2015|\n",
      "|   3|    4|2015|\n",
      "|  27|    5|2014|\n",
      "|  28|    5|2014|\n",
      "|   7|   10|2014|\n",
      "|  12|    3|2015|\n",
      "|  24|    1|2015|\n",
      "|  31|    7|2014|\n",
      "|  29|    5|2014|\n",
      "|   5|   12|2014|\n",
      "|  24|    4|2015|\n",
      "+----+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ts.select(F.day(F.col(\"datetime\")).alias(\"date\"), \\\n",
    "             F.month(F.col(\"datetime\")).alias(\"month\"), \\\n",
    "             F.year(F.col(\"datetime\")).alias(\"year\") ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11441521-3cf2-4819-a390-fcdad7fbb037",
   "metadata": {},
   "source": [
    "## Count total sold year wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "794ed1d1-0d21-4578-a161-4d02e42594d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+\n",
      "|year|yearly_sold_out|\n",
      "+----+---------------+\n",
      "|2015|6980           |\n",
      "|2014|14633          |\n",
      "+----+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_ts.groupBy(F.year(\"datetime\").alias(\"year\")).agg(F.count(\"id\").alias(\"yearly_sold_out\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9fa26c4-6ce8-447c-8d3d-06d6120115b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " auto-mpg.csv\t\t\t\t  kc_house_data.csv\n",
      " brand-laptops-dataset.zip\t\t  laptops.csv\n",
      " covid.json\t\t\t\t  train_info.csv\n",
      " Employee.csv\t\t\t\t  train_schedule.csv\n",
      "'IEA-EV-dataEV salesCarsHistorical.csv'   train_schedule.csv.zip\n",
      " indian_states_code_name_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "!ls datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f986300-c4e0-4e0a-80b4-649059ff33f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------------+----------+------+------------+----------+------+----------------------------+\n",
      "|mpg|cylinders|displacement|horsepower|weight|acceleration|model year|origin|car name                    |\n",
      "+---+---------+------------+----------+------+------------+----------+------+----------------------------+\n",
      "|18 |8        |307         |130       |3504  |12          |70        |1     |chevrolet chevelle malibu   |\n",
      "|15 |8        |350         |165       |3693  |11.5        |70        |1     |buick skylark 320           |\n",
      "|18 |8        |318         |150       |3436  |11          |70        |1     |plymouth satellite          |\n",
      "|16 |8        |304         |150       |3433  |12          |70        |1     |amc rebel sst               |\n",
      "|17 |8        |302         |140       |3449  |10.5        |70        |1     |ford torino                 |\n",
      "|15 |8        |429         |198       |4341  |10          |70        |1     |ford galaxie 500            |\n",
      "|14 |8        |454         |220       |4354  |9           |70        |1     |chevrolet impala            |\n",
      "|14 |8        |440         |215       |4312  |8.5         |70        |1     |plymouth fury iii           |\n",
      "|14 |8        |455         |225       |4425  |10          |70        |1     |pontiac catalina            |\n",
      "|15 |8        |390         |190       |3850  |8.5         |70        |1     |amc ambassador dpl          |\n",
      "|15 |8        |383         |170       |3563  |10          |70        |1     |dodge challenger se         |\n",
      "|14 |8        |340         |160       |3609  |8           |70        |1     |plymouth 'cuda 340          |\n",
      "|15 |8        |400         |150       |3761  |9.5         |70        |1     |chevrolet monte carlo       |\n",
      "|14 |8        |455         |225       |3086  |10          |70        |1     |buick estate wagon (sw)     |\n",
      "|24 |4        |113         |95        |2372  |15          |70        |3     |toyota corona mark ii       |\n",
      "|22 |6        |198         |95        |2833  |15.5        |70        |1     |plymouth duster             |\n",
      "|18 |6        |199         |97        |2774  |15.5        |70        |1     |amc hornet                  |\n",
      "|21 |6        |200         |85        |2587  |16          |70        |1     |ford maverick               |\n",
      "|27 |4        |97          |88        |2130  |14.5        |70        |3     |datsun pl510                |\n",
      "|26 |4        |97          |46        |1835  |20.5        |70        |2     |volkswagen 1131 deluxe sedan|\n",
      "+---+---------+------------+----------+------+------------+----------+------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "        .option(\"schemaInfer\", True)\\\n",
    "        .option(\"header\", True)\\\n",
    "        .load(\"datasets/auto-mpg.csv\")\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a12a48e-6849-42db-b144-155ca8c61f52",
   "metadata": {},
   "source": [
    "## Read another dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb70cc34-7a54-4dbc-aa17-51b0c9cef2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5fa6da94-8b5f-4d97-b291-274f79dae75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/laptops.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('datasets'):\n",
    "    # print(f\"dirname: {dirname}, unknown:{_}, filenames: {filenames}\")\n",
    "    for filename in filenames:\n",
    "        if filename==\"laptops.csv\":\n",
    "            print(os.path.join(dirname, filename))\n",
    "            df = spark.read.format(\"csv\")\\\n",
    "                        .option(\"InferSchema\", True)\\\n",
    "                        .option(\"header\", True)\\\n",
    "                        .load(f\"{os.path.join(dirname, filename)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad9ee6b0-7f88-4471-966f-764237299dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------------------+-----+------+---------------+--------------+---------+-----------+----------+--------------------+------------------------+----------------------+--------------------------+---------+----------+---------------+------------+----------------+-----------------+-------+----------------+\n",
      "|index|brand|               Model|Price|Rating|processor_brand|processor_tier|num_cores|num_threads|ram_memory|primary_storage_type|primary_storage_capacity|secondary_storage_type|secondary_storage_capacity|gpu_brand|  gpu_type|is_touch_screen|display_size|resolution_width|resolution_height|     OS|year_of_warranty|\n",
      "+-----+-----+--------------------+-----+------+---------------+--------------+---------+-----------+----------+--------------------+------------------------+----------------------+--------------------------+---------+----------+---------------+------------+----------------+-----------------+-------+----------------+\n",
      "|    1|tecno|Tecno Megabook T1...|23990|    63|          intel|       core i3|        2|          4|         8|                 SSD|                     512|  No secondary storage|                         0|    intel|integrated|          false|        15.6|            1920|             1080|windows|               1|\n",
      "|    2|tecno|Tecno Megabook T1...|35990|    67|          intel|       core i7|        4|          8|        16|                 SSD|                    1024|  No secondary storage|                         0|    intel|integrated|          false|        15.6|            1920|             1080|windows|               1|\n",
      "+-----+-----+--------------------+-----+------+---------------+--------------+---------+-----------+----------+--------------------+------------------------+----------------------+--------------------------+---------+----------+---------------+------------+----------------+-----------------+-------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b5dffde-aaca-4d13-8cac-26223d71d10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'brand',\n",
       " 'Model',\n",
       " 'Price',\n",
       " 'Rating',\n",
       " 'processor_brand',\n",
       " 'processor_tier',\n",
       " 'num_cores',\n",
       " 'num_threads',\n",
       " 'ram_memory',\n",
       " 'primary_storage_type',\n",
       " 'primary_storage_capacity',\n",
       " 'secondary_storage_type',\n",
       " 'secondary_storage_capacity',\n",
       " 'gpu_brand',\n",
       " 'gpu_type',\n",
       " 'is_touch_screen',\n",
       " 'display_size',\n",
       " 'resolution_width',\n",
       " 'resolution_height',\n",
       " 'OS',\n",
       " 'year_of_warranty']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1511125-d3c0-485c-ac2a-7453e7664c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Price: integer (nullable = true)\n",
      " |-- Rating: integer (nullable = true)\n",
      " |-- processor_brand: string (nullable = true)\n",
      " |-- processor_tier: string (nullable = true)\n",
      " |-- num_cores: integer (nullable = true)\n",
      " |-- num_threads: integer (nullable = true)\n",
      " |-- ram_memory: integer (nullable = true)\n",
      " |-- primary_storage_type: string (nullable = true)\n",
      " |-- primary_storage_capacity: integer (nullable = true)\n",
      " |-- secondary_storage_type: string (nullable = true)\n",
      " |-- secondary_storage_capacity: integer (nullable = true)\n",
      " |-- gpu_brand: string (nullable = true)\n",
      " |-- gpu_type: string (nullable = true)\n",
      " |-- is_touch_screen: boolean (nullable = true)\n",
      " |-- display_size: double (nullable = true)\n",
      " |-- resolution_width: integer (nullable = true)\n",
      " |-- resolution_height: integer (nullable = true)\n",
      " |-- OS: string (nullable = true)\n",
      " |-- year_of_warranty: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b6ceb4-6c3d-4f42-b25e-9ff5500795c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ec930-a453-491b-bbc2-d12c485eec77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71129d1c-0d50-4d22-af87-30a22718956b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42ff0640-13fb-41b5-ac0c-198d05c9470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[5 Apr 2018,012101], [09 Apr 2018, 015102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526b55c-61c1-434f-b546-520d1ba58dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OT 015102, 012101"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
